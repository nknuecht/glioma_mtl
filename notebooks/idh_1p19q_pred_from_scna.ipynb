{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nicholas Nuechterlein\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic Survival Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('../data/all_glioma_metadata_542x30.csv', index_col=0)\n",
    "metadata_df = metadata_df.set_index('tciaID')\n",
    "train_idx = metadata_df[metadata_df['phase'] == 'train'].index\n",
    "val_idx = metadata_df[metadata_df['phase'] == 'val'].index\n",
    "\n",
    "cna_full_df = pd.read_csv('../data/gistic-subtype-OS-1087-21546.csv', index_col=0)\n",
    "survival_df = cna_full_df['OS']\n",
    "cna_full_df = cna_full_df.drop(columns=['OS', 'subtype'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival predictions using extra/unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012 training samples and 75 validation samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389779f2fcd34d97809f3a9447675488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train = cna_full_df[~cna_full_df.index.isin(val_idx)]\n",
    "X_val = cna_full_df[cna_full_df.index.isin(val_idx)]\n",
    "\n",
    "print(X_train.shape[0], 'training samples and', X_val.shape[0], 'validation samples')\n",
    "\n",
    "# loop through PCA projections with different numbers of components in [2, 50]\n",
    "for n_components in tqdm([i for i in range(2, 50)]):\n",
    "    # PCA on the entire dataset (1087 - 75 (val)) | of the \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_valid_pca = pca.transform(X_val)\n",
    "    \n",
    "    # make X_train back into a dataframe to make sure the labels line up with the samples\n",
    "    pca_columns = ['pca'+str(i) for i in range(n_components)]\n",
    "    X_train_pca_df = pd.DataFrame(data=X_train_pca, columns=pca_columns, index=X_train.index)\n",
    "    X_train_pca_df = X_train_pca_df[X_train_pca_df.index.isin(survival_df.index)]\n",
    "    train_pca_data_df = pd.concat([survival_df, X_train_pca_df], axis=1, join='inner').dropna()\n",
    "    \n",
    "    # do the same with the validation data\n",
    "    X_val_pca_df = pd.DataFrame(data=X_valid_pca, columns=pca_columns, index=X_val.index)\n",
    "    val_pca_data_df = pd.concat([survival_df, X_val_pca_df], axis=1, join='inner')\n",
    "    \n",
    "    ###########################################\n",
    "    ###### training and valiation data! #######\n",
    "    ###########################################\n",
    "    X_train_pca = train_pca_data_df[pca_columns]\n",
    "    y_os_train = train_pca_data_df['OS']\n",
    "    \n",
    "    X_val_pca = val_pca_data_df[pca_columns]\n",
    "    y_os_val = val_pca_data_df['OS']\n",
    "    ############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genomic predictions without unlabled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 training samples and 75 validation samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62244a678cb94af3b40afc2fecfb809b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = cna_full_df[cna_full_df.index.isin(train_idx)]\n",
    "X_val = cna_full_df[cna_full_df.index.isin(val_idx)]\n",
    "\n",
    "print(X_train.shape[0], 'training samples and', X_val.shape[0], 'validation samples')\n",
    "\n",
    "# loop through PCA projections with different numbers of components in [2, 50]\n",
    "for n_components in tqdm([i for i in range(2, 50)]):\n",
    "    # PCA on the entire dataset (1087 - 75 (val)) | of the \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_valid_pca = pca.transform(X_val)\n",
    "    \n",
    "    # make X_train back into a dataframe to make sure the labels line up with the samples\n",
    "    pca_columns = ['pca'+str(i) for i in range(n_components)]\n",
    "    X_train_pca_df = pd.DataFrame(data=X_train_pca, columns=pca_columns, index=X_train.index)\n",
    "    X_train_pca_df = X_train_pca_df[X_train_pca_df.index.isin(survival_df.index)]\n",
    "    train_pca_data_df = pd.concat([survival_df, X_train_pca_df], axis=1, join='inner')\n",
    "    \n",
    "    # do the same with the validation data\n",
    "    X_val_pca_df = pd.DataFrame(data=X_valid_pca, columns=pca_columns, index=X_val.index)\n",
    "    val_pca_data_df = pd.concat([survival_df, X_val_pca_df], axis=1, join='inner')\n",
    "    \n",
    "    ###########################################\n",
    "    ###### training and valiation data! #######\n",
    "    ###########################################\n",
    "    X_train_pca = train_pca_data_df[pca_columns]\n",
    "    y_os_train = train_pca_data_df['OS']\n",
    "    \n",
    "    X_val_pca = val_pca_data_df[pca_columns]\n",
    "    y_os_val = val_pca_data_df['OS']\n",
    "    ############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic IDH predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_accuracies(preds, labels, probs=None, classes=['wildtype', 'oligo', 'mutant'], verbose=True):\n",
    "    preds = np.asarray(preds)\n",
    "    labels = np.asarray(labels)\n",
    "    probs = np.asarray(probs)\n",
    "    \n",
    "    class_acc_list = []\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_labels = labels[labels == i]\n",
    "        class_preds = preds[labels == i]\n",
    "        class_acc = np.sum(class_labels == class_preds)/class_labels.shape[0]\n",
    "        class_acc_list.append(class_acc)\n",
    "        if verbose:\n",
    "            print(class_name, 'acc:\\t', class_acc)\n",
    "    accuracy = np.sum(preds==labels)/labels.shape[0]\n",
    "    average_acc = np.mean(class_acc_list)\n",
    "    if verbose:\n",
    "        print('Average acc:\\t\\t', np.mean(class_acc_list))\n",
    "        print('Overall acc:\\t\\t', np.sum(preds==labels)/labels.shape[0])\n",
    "    \n",
    "    if len(classes) == 2 and probs is not None:\n",
    "        auc_score = roc_auc_score(labels, probs)\n",
    "        if verbose:\n",
    "            print('AUC:\\t', auc_score)\n",
    "    else:\n",
    "        auc_score = None\n",
    "    return accuracy, average_acc, auc_score\n",
    "        \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def lasso_regression(X_train, y_train, X_valid):\n",
    "    model = Lasso(alpha=0.01)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    # probs_valid = model.predict_proba(X_valid)  ## Lasso does not have a predict_proba method\n",
    "    probs_valid = model.predict(X_valid)\n",
    "    return preds_valid, probs_valid\n",
    "\n",
    "def logistic_regression(X_train, y_train, X_valid):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    probs_valid = model.predict_proba(X_valid)\n",
    "    return preds_valid, probs_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df = pd.read_csv('../data/all_glioma_metadata_542x30.csv', index_col=0)\n",
    "metadata_df = metadata_df.set_index('tciaID')\n",
    "train_idx = metadata_df[metadata_df['phase'] == 'train'].index\n",
    "val_idx = metadata_df[metadata_df['phase'] == 'val'].index\n",
    "\n",
    "cna_full_df = pd.read_csv('../data/gistic-subtype-OS-1087-21546.csv', index_col=0)\n",
    "survival_df = cna_full_df['OS']\n",
    "cna_full_df = cna_full_df.drop(columns=['OS', 'subtype'])\n",
    "\n",
    "idh_df = pd.read_csv('../data/idh_825x2.csv', index_col=0)\n",
    "idh_df = idh_df.sum(axis=1)\n",
    "idh_df[idh_df > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genomic predictions with unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea471c1ee97e415f8bc957e991105ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best average_acc: 0.9131944444444444 \t| dim: 2 \t| AUC 0.9652777777777777\n",
      "best average_acc: 0.931712962962963 \t| dim: 3 \t| AUC 0.9733796296296297\n",
      "best average_acc: 0.947337962962963 \t| dim: 8 \t| AUC 0.9826388888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_train = cna_full_df[~cna_full_df.index.isin(val_idx)]\n",
    "X_val = cna_full_df[cna_full_df.index.isin(val_idx)]\n",
    "X_val = X_val[X_val.index.isin(idh_df.index)]\n",
    "\n",
    "avg_acc_dict, auc_dict = {}, {}\n",
    "best_avg_acc = 0\n",
    "\n",
    "print(X_train.shape[0], 'samples')\n",
    "for n_components in tqdm([i for i in range(2, 50)]):\n",
    "    # PCA on the entire dataset (1087 - 75 (val)) | of the \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_valid_pca = pca.transform(X_val)\n",
    "    \n",
    "    # make X_train back into a dataframe to make sure the labels line up with the samples\n",
    "    pca_columns = ['pca'+str(i) for i in range(n_components)]\n",
    "    X_train_pca_df = pd.DataFrame(data=X_train_pca, columns=pca_columns, index=X_train.index)\n",
    "    X_train_pca_df = X_train_pca_df[X_train_pca_df.index.isin(idh_df.index)]\n",
    "    \n",
    "    # join the labels back with the training data (again, to make sure they line up)\n",
    "    train_pca_data_df = pd.concat([idh_df, X_train_pca_df], axis=1, join='inner')\n",
    "    \n",
    "    # # logistic regression + L2 \n",
    "    preds_lr, probs_lr = logistic_regression(X_train=train_pca_data_df[pca_columns], \n",
    "                                             y_train=train_pca_data_df[0], \n",
    "                                             X_valid=X_valid_pca)\n",
    "    \n",
    "    X_val_pca_df = pd.DataFrame(data=X_valid_pca, columns=pca_columns, index=X_val.index)\n",
    "    X_val_pca_df = X_val_pca_df[X_val_pca_df.index.isin(idh_df.index)]\n",
    "    val_pca_data_df = pd.concat([idh_df, X_val_pca_df], axis=1, join='inner')\n",
    "\n",
    "    accuracy, average_acc, auc_score = class_accuracies(preds=preds_lr, \n",
    "                                                        labels=val_pca_data_df[0], \n",
    "                                                        probs=probs_lr[:,1], \n",
    "                                                        classes=['wildtype', 'mutant'],\n",
    "                                                       verbose=False)\n",
    "    if average_acc > best_avg_acc:\n",
    "        print('best average_acc:', average_acc, '\\t| dim:', n_components, '\\t| AUC', auc_score)\n",
    "        best_avg_acc = average_acc\n",
    "    \n",
    "    avg_acc_dict[n_components] = average_acc\n",
    "    auc_dict[n_components] = auc_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We pick the AUC with the highest accuracy\n",
      "AUC 0.9606481481481481\n",
      "Average ACC 0.947337962962963\n"
     ]
    }
   ],
   "source": [
    "print('We pick the AUC with the highest accuracy')\n",
    "print('AUC', auc_dict[25])\n",
    "print('Average ACC', avg_acc_dict[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genomic predictions without unlabled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6cbdc4472944b181f04149830de808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best average_acc: 0.9131944444444444 \t| dim: 2 \t| AUC 0.96875\n",
      "best average_acc: 0.916087962962963 \t| dim: 3 \t| AUC 0.9710648148148149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best average_acc: 0.9346064814814814 \t| dim: 14 \t| AUC 0.9699074074074074\n",
      "best average_acc: 0.9658564814814814 \t| dim: 15 \t| AUC 0.9594907407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/gws/beibin/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "avg_acc_dict, auc_dict = {}, {}\n",
    "best_avg_acc = 0\n",
    "from sklearn.decomposition import PCA\n",
    "X_train = cna_full_df[cna_full_df.index.isin(train_idx)]\n",
    "X_val = cna_full_df[cna_full_df.index.isin(val_idx)]\n",
    "X_val = X_val[X_val.index.isin(idh_df.index)]\n",
    "\n",
    "print(X_train.shape[0], 'samples')\n",
    "for n_components in tqdm([i for i in range(2, 50)]):\n",
    "    # PCA on the train dataset (160) | of the \n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_valid_pca = pca.transform(X_val)\n",
    "    \n",
    "    # make X_train back into a dataframe to make sure the labels line up with the samples\n",
    "    pca_columns = ['pca'+str(i) for i in range(n_components)]\n",
    "    X_train_pca_df = pd.DataFrame(data=X_train_pca, columns=pca_columns, index=X_train.index)\n",
    "    X_train_pca_df = X_train_pca_df[X_train_pca_df.index.isin(idh_df.index)]\n",
    "    \n",
    "    # join the labels back with the training data (again, to make sure they line up)\n",
    "    train_pca_data_df = pd.concat([idh_df, X_train_pca_df], axis=1, join='inner')\n",
    "    \n",
    "    # logistic regression + L2\n",
    "    preds_lr, probs_lr = logistic_regression(X_train=train_pca_data_df[pca_columns], \n",
    "                                             y_train=train_pca_data_df[0], \n",
    "                                             X_valid=X_valid_pca)\n",
    "    \n",
    "    X_val_pca_df = pd.DataFrame(data=X_valid_pca, columns=pca_columns, index=X_val.index)\n",
    "    X_val_pca_df = X_val_pca_df[X_val_pca_df.index.isin(idh_df.index)]\n",
    "    val_pca_data_df = pd.concat([idh_df, X_val_pca_df], axis=1, join='inner')\n",
    "\n",
    "    accuracy, average_acc, auc_score = class_accuracies(preds=preds_lr, \n",
    "                                                        labels=val_pca_data_df[0], \n",
    "                                                        probs=probs_lr[:,1], \n",
    "                                                        classes=['wildtype', 'mutant'],\n",
    "                                                       verbose=False)\n",
    "    if average_acc > best_avg_acc:\n",
    "        print('best average_acc:', average_acc, '\\t| dim:', n_components, '\\t| AUC', auc_score)\n",
    "        best_avg_acc = average_acc\n",
    "    \n",
    "    avg_acc_dict[n_components] = average_acc\n",
    "    auc_dict[n_components] = auc_score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
