{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import transform # io, \n",
    "import PIL\n",
    "import math\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "import pickle\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from datasets import GeneralDataset\n",
    "import Transforms as myTransforms\n",
    "\n",
    "# from visualize import show_2Dbatch, show_4channel_batch, show_3Dbatch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(metadata_df, task='idh', mtl = False):\n",
    "    \n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "    Arguments\n",
    "    ---------\n",
    "    metadata_df:   For each sample this dataframe indicates\n",
    "                        1) whether it is in the labeled training, unlabeled training set, or valiation set\n",
    "                        2) its idh status, and 1p19q status\n",
    "    task:          Either 'idh' or '1p19q'\n",
    "    mtl:           If True, MRI data without IDH mutation or 1p/19q co-deletion labels will be included in the traing set\n",
    "    \n",
    "    Outputs\n",
    "    ---------\n",
    "    train_df:      Dataframe of training samples\n",
    "    val_df:        Dataframe of validation samples\n",
    "    classes:       Names of numerical labels\n",
    "    '''\n",
    "    \n",
    "    # validation set\n",
    "    if task == 'idh':\n",
    "        classes = ['wildtype', 'mutant']\n",
    "        val_df = glioma_metadata_df.loc[(glioma_metadata_df['phase'] == 'val') \n",
    "                                        & (glioma_metadata_df[task].isin([0,1]))] # check whether IDH status known\n",
    "    elif task == '1p19q':\n",
    "        classes = ['non-codel', 'oligo']\n",
    "        val_df = glioma_metadata_df.loc[glioma_metadata_df['phase'] == 'val']\n",
    "    \n",
    "    # training set\n",
    "    if mtl:\n",
    "        train_df = glioma_metadata_df.loc[glioma_metadata_df['phase'].isin(['train', 'unlabeled train'])]\n",
    "    else:\n",
    "        train_df = glioma_metadata_df.loc[(glioma_metadata_df['phase'] == 'train') \n",
    "                                          & (glioma_metadata_df[task].isin([0,1]))] # only labeled data (0/1)\n",
    "\n",
    "    return train_df, val_df, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 112\n"
     ]
    }
   ],
   "source": [
    "# task = '1p19q'\n",
    "task = 'idh'\n",
    "\n",
    "if task == 'idh':\n",
    "    classes = ['wildtype', 'mutant']\n",
    "elif task == '1p19q':\n",
    "    classes = ['non-codel', 'oligo']\n",
    "else:\n",
    "    print('task?')\n",
    "\n",
    "brats2tcia_df = pd.read_csv('../../miccai_clean/data/brats2tcia_df_542x1.csv', index_col=0)\n",
    "\n",
    "# old way to get train/val\n",
    "# glioma_metadata_df = pd.read_csv('../../miccai_clean/data/all_glioma_metadata_542x30.csv', index_col=0)\n",
    "# glioma_metadata_df = glioma_metadata_df.rename(columns={'OS.time':'OS', '_EVENT':'OS_EVENT'})\n",
    "# val_df = glioma_metadata_df[(glioma_metadata_df['phase'] == 'val') & (glioma_metadata_df['inferred_subtype'] == 0)]\n",
    "# train_df = glioma_metadata_df[(glioma_metadata_df['phase'] == 'train') & (glioma_metadata_df['inferred_subtype'] == 0)]\n",
    "\n",
    "# new way to get train/val\n",
    "glioma_metadata_df = pd.read_csv('../data/glioma_metadata.csv', index_col=0) # metadata file\n",
    "glioma_metadata_df.loc[['Brats18_TCIA09_462_1', 'Brats18_TCIA10_236_1'], 'idh'] = 1 ######\n",
    "# # glioma_metadata_df['idh_cluster'] = glioma_metadata_df['idh']\n",
    "# train_df = glioma_metadata_df.loc[(glioma_metadata_df['phase'] == 'train') \n",
    "#                                           & (glioma_metadata_df[task].isin([0,1]))] # only labeled data (0/1)\n",
    "# val_df = glioma_metadata_df.loc[(glioma_metadata_df['phase'] == 'val') \n",
    "#                                         & (glioma_metadata_df[task].isin([0,1]))] # check whether IDH status known\n",
    "\n",
    "mtl = False\n",
    "train_df, val_df, classes = get_data_splits(metadata_df=glioma_metadata_df, task=task, mtl=mtl)\n",
    "\n",
    "csv_files = {'train':train_df, 'val':val_df, 'data':glioma_metadata_df}\n",
    "\n",
    "\n",
    "\n",
    "genomic_csv_files = {'train':'../data/MGL/MGL_235x50.csv', \n",
    "             'val':'../data/MGL/MGL_235x50.csv',\n",
    "             'data':'../data/MGL/MGL_235x50.csv'}\n",
    "\n",
    "image_train_dir = '../data/mr_data/train/'\n",
    "image_dir = '../data/all_brats_scans/'\n",
    "# image_dir = '/data/nick/all_brats_scans/'\n",
    "# image_dir = '../data/whitestrip_n4_mr_data/'\n",
    "\n",
    "# cluster_column= task + '_cluster'\n",
    "\n",
    "train_batch_size = 4\n",
    "val_batch_size = 4\n",
    "data_batch_size = 1\n",
    "\n",
    "\n",
    "resize_shape = (64, 64, 64)\n",
    "# resize_shape = (16, 16, 16)\n",
    "channels = 1\n",
    "interpolation = 1\n",
    "\n",
    "shuffle = True\n",
    "shuffle_data = False\n",
    "\n",
    "modality = 't1ce'\n",
    "dataformat='modality3D'\n",
    "\n",
    "# label = 'idh_cluster'\n",
    "label = 'idh'\n",
    "\n",
    "print('Training size:', len(csv_files['train']))\n",
    "null_genomic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:\t\t idh\n",
      "mtl:\t\t False\n",
      "dataformat:\t modality3D\n",
      "channels:\t 1\n",
      "modality:\t t1ce\n",
      "resize_shape:\t (64, 64, 64)\n",
      "null_genomic:\t False\n"
     ]
    }
   ],
   "source": [
    "print('task:\\t\\t', task)\n",
    "print('mtl:\\t\\t', mtl)\n",
    "print('dataformat:\\t', dataformat)\n",
    "print('channels:\\t', channels)\n",
    "print('modality:\\t', modality)\n",
    "print('resize_shape:\\t', resize_shape)\n",
    "print('null_genomic:\\t', null_genomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'modality3D'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tciaID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brats18_2013_0_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_2013_10_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_2013_11_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_2013_12_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_2013_13_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_WashU_W051_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_WashU_W053_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_WashU_W061_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_WashU_W065_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brats18_WashU_W082_1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tciaID\n",
       "Brats18_2013_0_1        NaN\n",
       "Brats18_2013_10_1       NaN\n",
       "Brats18_2013_11_1       NaN\n",
       "Brats18_2013_12_1       NaN\n",
       "Brats18_2013_13_1       NaN\n",
       "...                     ...\n",
       "Brats18_WashU_W051_1    NaN\n",
       "Brats18_WashU_W053_1    NaN\n",
       "Brats18_WashU_W061_1    NaN\n",
       "Brats18_WashU_W065_1    NaN\n",
       "Brats18_WashU_W082_1    NaN\n",
       "\n",
       "[542 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brats2tcia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## new files\n",
    "# g_metadata_df = pd.read_csv('../data/glioma_metadata.csv', index_col=0) # metadata file\n",
    "# g_metadata_df.loc[['Brats18_TCIA09_462_1', 'Brats18_TCIA10_236_1'], 'idh'] = 1 ######\n",
    "# t_df = train_df = g_metadata_df.loc[(g_metadata_df['phase'] == 'train') \n",
    "#                                           & (g_metadata_df[task].isin([0,1]))] # only labeled data (0/1)\n",
    "\n",
    "# ## old files\n",
    "# glioma_metadata_df = pd.read_csv('../../miccai_clean/data/all_glioma_metadata_542x30.csv', index_col=0)\n",
    "# glioma_metadata_df = glioma_metadata_df.rename(columns={'OS.time':'OS', '_EVENT':'OS_EVENT'})\n",
    "# val_df = glioma_metadata_df[(glioma_metadata_df['phase'] == 'val') & (glioma_metadata_df['inferred_subtype'] == 0)]\n",
    "# train_df = glioma_metadata_df[(glioma_metadata_df['phase'] == 'train') & (glioma_metadata_df['inferred_subtype'] == 0)]\n",
    "\n",
    "# # check to see if they are the same!\n",
    "# df = pd.concat([train_df['idh_cluster'], t_df['idh']], axis=1, join='inner')\n",
    "# df.loc[df['idh_cluster'] != df['idh']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wildtype', 'mutant']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformations = myTransforms.Compose([\n",
    "        myTransforms.MinMaxNormalize(),\n",
    "        myTransforms.ScaleToFixed((1, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=interpolation, \n",
    "                                  channels=channels),\n",
    "        myTransforms.ZeroSprinkle(prob_zero=0.2, prob_true=0.8),\n",
    "#         myTransforms.ZeroChannel(prob_zero=0.5),\n",
    "        myTransforms.RandomFlip(),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "seg_transformations = myTransforms.Compose([\n",
    "    myTransforms.ScaleToFixed((1, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=0, \n",
    "                                  channels=1),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "val_transformations = myTransforms.Compose([\n",
    "        myTransforms.MinMaxNormalize(),\n",
    "        myTransforms.ScaleToFixed((1, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=interpolation, \n",
    "                                  channels=channels),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "data_transforms = {'train': train_transformations,\n",
    "                    'val':   val_transformations,\n",
    "                    'data':   val_transformations,\n",
    "                   'seg': seg_transformations,\n",
    "                  }\n",
    "\n",
    "\n",
    "\n",
    "transformed_dataset_train = GeneralDataset(csv_file=csv_files['train'],\n",
    "                                           root_dir=image_dir,\n",
    "                                           genomic_csv_file = genomic_csv_files['train'],\n",
    "                                           transform=data_transforms['train'],\n",
    "                                           seg_transform=data_transforms['seg'],\n",
    "                                           label=label,\n",
    "                                           classes=classes,\n",
    "                                           dataformat=dataformat,\n",
    "                                           returndims=resize_shape,\n",
    "                                           brats2tcia_df=brats2tcia_df,\n",
    "                                           modality=modality,\n",
    "                                           null_genomic=True)\n",
    "\n",
    "transformed_dataset_val = GeneralDataset(csv_file=csv_files['val'],\n",
    "                                         root_dir=image_dir,\n",
    "                                         genomic_csv_file = genomic_csv_files['val'],\n",
    "                                         transform=data_transforms['val'],\n",
    "                                         seg_transform=data_transforms['seg'],\n",
    "                                         classes=classes,\n",
    "                                         label=label,\n",
    "                                         dataformat=dataformat,\n",
    "                                         returndims=resize_shape,\n",
    "                                         brats2tcia_df=brats2tcia_df,\n",
    "                                         modality=modality,\n",
    "                                         null_genomic=True)\n",
    "\n",
    "\n",
    "transformed_dataset_data = GeneralDataset(csv_file=csv_files['data'],\n",
    "                                         root_dir=image_dir,\n",
    "                                          genomic_csv_file = genomic_csv_files['data'],\n",
    "                                         transform=data_transforms['data'],\n",
    "                                          seg_transform=data_transforms['seg'],\n",
    "                                         classes=classes,\n",
    "                                          label=label,\n",
    "                                         dataformat=dataformat,\n",
    "                                         returndims=resize_shape,\n",
    "                                         brats2tcia_df=brats2tcia_df,\n",
    "                                          modality=modality,\n",
    "                                         null_genomic=True)\n",
    "\n",
    "image_datasets = {'train':transformed_dataset_train, \n",
    "                  'val':transformed_dataset_val,\n",
    "                  'data':transformed_dataset_data}\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(image_datasets['train'], batch_size=train_batch_size, shuffle=shuffle, num_workers=4)\n",
    "dataloader_val = DataLoader(image_datasets['val'], batch_size=val_batch_size, shuffle=shuffle, num_workers=4)\n",
    "dataloader_data = DataLoader(image_datasets['data'], batch_size=data_batch_size, shuffle=shuffle_data, num_workers=4)\n",
    "\n",
    "dataloaders = {'train':dataloader_train, 'val':dataloader_val, 'data':dataloader_data}\n",
    "\n",
    "dataset_sizes = {'train':len(image_datasets['train']), \n",
    "                 'val':len(image_datasets['val']), \n",
    "                 'data':len(image_datasets['data'])}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtype_dict = {0:'wildtype', 1:'val'}\n",
    "# for i, data in enumerate(dataloaders['data']):\n",
    "# #     (image_slices, image_volumes), labels = data\n",
    "#     (image, seg_image, genomic_data), cluster, bratsID = data\n",
    "    \n",
    "#     shape = image.shape\n",
    "\n",
    "#     img = image[:,:,:,int(shape[-1]/2)].squeeze()\n",
    "#     img = utils.make_grid(img)\n",
    "#     img = img.detach().cpu().numpy()\n",
    "    \n",
    "#     plt.figure(figsize=(15, 8))\n",
    "#     plt.imshow(np.hstack([img[0].T, img[1].T, img[2].T, img[3]]), cmap='Greys_r')\n",
    "    \n",
    "    \n",
    "#     print('**', image.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([55, 57]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_df['idh'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboad: 3D_idh_t1ce_64x64x64_bs-4_newdataloader_only-gt-idh\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "img_dims = str(resize_shape[0]) + 'x' + str(resize_shape[1]) + 'x' + str(resize_shape[2])\n",
    "model_outfile_dir = '3D_' + task + '_' + modality + '_' + img_dims +'_bs-' + str(train_batch_size) + '_newdataloader_only-gt-idh'\n",
    "print('tensorboad:', model_outfile_dir)\n",
    "writer = SummaryWriter('runs1/'+model_outfile_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss weights: tensor([1.0364, 1.0000], device='cuda:0')\n",
      "Iteration 0\n",
      "training . . . \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19c6803488e4a17aca506a0a6595259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best ACC:\t 0.5283564814814814 \tin epoch 0\n",
      "New Best AUC-acc aveage:\t 0.6663773148148148 \tin epoch 0\n",
      "New Best ACC:\t 0.7552083333333333 \tin epoch 1\n",
      "New Best AUC-acc aveage:\t 0.7769097222222221 \tin epoch 1\n",
      "New Best ACC:\t 0.7795138888888888 \tin epoch 3\n",
      "New Best AUC-acc aveage:\t 0.7925347222222221 \tin epoch 3\n",
      "New Best ACC:\t 0.8049768518518519 \tin epoch 6\n",
      "New Best AUC:\t 0.863425925925926 \tin epoch 6\n",
      "New Best AUC-acc aveage:\t 0.834201388888889 \tin epoch 6\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f86ac8ab5580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     model, best_wts, best_auc, best_acc, best_auc_acc = train(model=esp_model, \n\u001b[0m\u001b[1;32m     53\u001b[0m                        \u001b[0mdataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                        \u001b[0mdata_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fh/fast/holland_e/grp/HollandLabShared/Nicholas/repos/glioma_mtl/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloaders, data_transforms, criterion, optimizer, scheduler, dataset_sizes, writer, num_epochs, verbose, device, channels, classes, pad, resize_shape, volume_val, weight_dir, weight_outfile_prefix)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# for i, data in tqdm(enumerate(dataloaders[phase])):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenomic_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbratsID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/fhPython/3.8.2-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/fhPython/3.8.2-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/fhPython/3.8.2-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/fhPython/3.8.2-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/Python/3.8.2-GCCcore-9.3.0/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/Python/3.8.2-GCCcore-9.3.0/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/Python/3.8.2-GCCcore-9.3.0/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/Python/3.8.2-GCCcore-9.3.0/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/software/Python/3.8.2-GCCcore-9.3.0/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "best_model_loc = '../pretrained/espnet_3d_brats.pth'\n",
    "\n",
    "# cluster_df = csv_files['train'][task + '_cluster']\n",
    "cluster_df = csv_files['train'][task]\n",
    "_, cnts = np.unique(cluster_df, return_counts=True)\n",
    "loss_weights = (np.ones(num_classes)/cnts)*np.max(cnts)\n",
    "loss_weights = torch.FloatTensor(loss_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=loss_weights)\n",
    "print('loss weights:', loss_weights)\n",
    "\n",
    "\n",
    "from train import train\n",
    "best_auc_list, best_acc_list, best_auc_acc_list = [], [], []\n",
    "epochs = 50\n",
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    print('Iteration', i)\n",
    "    \n",
    "    \n",
    "    # resize_shape = (64, 64, 64)\n",
    "\n",
    "    from models.Models import SegModel\n",
    "    \n",
    "    esp_model = SegModel(best_model_loc=best_model_loc, \n",
    "                         inp_res = resize_shape, \n",
    "                         num_classes=num_classes, \n",
    "                         channels=4)\n",
    "    \n",
    "    level0_weight = esp_model.espnet.level0.conv.weight[:, 0].unsqueeze(1)\n",
    "    esp_model.espnet.level0.conv = nn.Conv3d(1, 16, kernel_size=(7, 7, 7), \n",
    "                                             stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n",
    "\n",
    "    esp_model.espnet.level0.conv.weight = nn.Parameter(level0_weight)\n",
    "    esp_model = esp_model.to(device=device)\n",
    "\n",
    "    optimizer_esp = optim.Adam(esp_model.parameters(), lr=0.0005) # change to adam\n",
    "#     exp_scheduler = optim.lr_scheduler.StepLR(optimizer_esp, step_size=7, gamma=0.1)\n",
    "\n",
    "    exp_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer_esp, \n",
    "                                                         mode='min', \n",
    "                                                         factor=0.1, \n",
    "                                                         patience=10, # number of epochs with no change \n",
    "                                                         verbose=True, \n",
    "                                                         threshold=0.0001, \n",
    "                                                         threshold_mode='rel', \n",
    "                                                         cooldown=0, \n",
    "                                                         min_lr=0, \n",
    "                                                         eps=1e-08)\n",
    "\n",
    "\n",
    "    model, best_wts, best_auc, best_acc, best_auc_acc = train(model=esp_model, \n",
    "                       dataloaders=dataloaders,\n",
    "                       data_transforms=data_transforms,\n",
    "                       criterion = criterion, \n",
    "                       optimizer=optimizer_esp, \n",
    "                       scheduler=exp_scheduler,\n",
    "                       writer=writer,\n",
    "                       num_epochs=epochs, \n",
    "                       verbose=False, \n",
    "                       device=device,\n",
    "                       dataset_sizes=dataset_sizes,\n",
    "                       channels=1,\n",
    "                       resize_shape=resize_shape,\n",
    "                       classes=class_names,\n",
    "#                        use_probs=True,\n",
    "                       volume_val=False,\n",
    "#                        percentile=50,\n",
    "                       weight_outfile_prefix=model_outfile_dir)\n",
    "    del esp_model\n",
    "    del model\n",
    "    \n",
    "    best_auc_list.append(best_auc)\n",
    "    best_acc_list.append(best_acc)\n",
    "    best_auc_acc_list.append(best_auc_acc)\n",
    "    \n",
    "    \n",
    "    if not os.path.exists('../model_weights/results/'):\n",
    "        os.makedirs('../model_weights/results/')\n",
    "    \n",
    "    results_outfile_dir = model_outfile_dir + '_epochs-' + str(epochs) +'_iterations-' + str(iterations)\n",
    "    with open('../model_weights/results/auc_' + results_outfile_dir + '.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(best_auc_list, fp)\n",
    "    with open('../model_weights/results/acc_' + results_outfile_dir + '.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(best_acc_list, fp)\n",
    "    with open('../model_weights/results/avg_auc_acc_' + results_outfile_dir + '.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(best_auc_acc_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Modality: T1ce (March 8th)\n",
    "\n",
    "50 epoch\n",
    "\n",
    "10 loops\n",
    "\n",
    "3D_idh_t1ce_64x64x64_bs-4_newdataloader\n",
    "\n",
    "    best_auc_list std: 0.015810795227100584\n",
    "    best_auc_list mean: 0.8700231481481481\n",
    "    \n",
    "    acc std: 0.02270886719744711\n",
    "    best_acc_list mean: 0.8197337962962962\n",
    "    \n",
    "    \n",
    " \n",
    "---\n",
    "3D_idh_t1ce_64x64x64_bs-4_newdataloader_only-gt-idh\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D_idh_t1ce_64x64x64_bs-4_newdataloader_only-gt-idh\n",
    "\n",
    "    best_auc_list std: 0.016007827330301965\n",
    "    best_auc_list mean: 0.8934027777777779\n",
    "    \n",
    "    acc std: 0.02130698705091663\n",
    "    best_acc_list mean: 0.842013888888889\n",
    "    \n",
    "    \n",
    " \n",
    "---\n",
    "\n",
    "tensorboad: 3D_1p19q_t1ce_64x64x64_bs-4_newdataloader_only-gt-idh\n",
    "\n",
    "    best_auc_list std: 0.05383139511559983\n",
    "    best_auc_list mean: 0.7228787878787879\n",
    "    \n",
    "    acc std: 0.04590909090909092\n",
    "    best_acc_list mean: 0.5153030303030304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(best_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
