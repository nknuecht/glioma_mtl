{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import transform # io, \n",
    "# import PIL\n",
    "# import math\n",
    "# from glob import glob\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision import transforms, utils, datasets, models\n",
    "# import torch.optim as optim\n",
    "# from torch.optim import lr_scheduler\n",
    "# import torchvision\n",
    "# import pickle\n",
    "\n",
    "# # Ignore warnings\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# %matplotlib inline\n",
    "# plt.ion()   # interactive mode\n",
    "\n",
    "\n",
    "# from visualize import show_2Dbatch, show_4channel_batch, show_3Dbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# can revome the lines that need these\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from datasets import GeneralDataset\n",
    "import Transforms as myTransforms\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size 112\n"
     ]
    }
   ],
   "source": [
    "# choose task: either 'idh' or '1p19q'\n",
    "task = 'idh'\n",
    "\n",
    "# choose mtl: True or False\n",
    "mtl = False\n",
    "\n",
    "# choose MR input\n",
    "## details ('crop3Dslice', 'modality3D'\n",
    "dataformat = 'modality3D'\n",
    "\n",
    "# modality (either None, 'T1ce', 'FLAIR', 'T2', 'T1', 'T1ce-T1')\n",
    "modality = None\n",
    "\n",
    "# metadata for all brats (including tcia) data\n",
    "glioma_metadata_df = pd.read_csv('../data/glioma_metadata.csv', index_col=0)\n",
    "glioma_metadata_df.loc[['Brats18_TCIA09_462_1', 'Brats18_TCIA10_236_1'], 'idh'] = 1\n",
    "\n",
    "if task == 'idh':\n",
    "    classes = ['wildtype', 'mutant']\n",
    "    val_df = glioma_metadata_df.loc[(glioma_metadata_df['phase'] == 'val') & (glioma_metadata_df['idh'].isin([0,1]))]\n",
    "    if mtl:\n",
    "        train_df = glioma_metadata_df.loc[glioma_metadata_df['phase'].isin(['train', 'unlabeled train'])]\n",
    "    else:\n",
    "        train_df = glioma_metadata_df.loc[(glioma_metadata_df['phase'] == 'train') & (glioma_metadata_df['idh'].isin([0,1]))]\n",
    "        \n",
    "elif task == '1p19q':\n",
    "    classes = ['non-codel', 'oligo']\n",
    "    val_df = glioma_metadata_df.loc[glioma_metadata_df['phase'] == 'val']\n",
    "\n",
    "# map between brats dataset and tcia data (tcia data is avalible for a subset of the brats patients)\n",
    "# brats2tcia_df = pd.read_csv('../data/brats2tcia_df_542x1.csv', index_col=0)\n",
    "brats2tcia_df =glioma_metadata_df['tciaID']\n",
    "\n",
    "\n",
    "# these are labeled files (they were paths in old dataloader) but they are dataframes\n",
    "csv_files = {'train':train_df, 'val':val_df, 'data':glioma_metadata_df}\n",
    "\n",
    "\n",
    "genomic_csv_files = {'train':'../data/MGL/MGL_235x50.csv', \n",
    "                     'val':'../data/MGL/MGL_235x50.csv',\n",
    "                     'data':'../data/MGL/MGL_235x50.csv'}\n",
    "\n",
    "\n",
    "image_dir = '../data/all_brats_scans/'\n",
    "cluster_column = task\n",
    "\n",
    "train_batch_size = 4\n",
    "val_batch_size = 4\n",
    "data_batch_size = 1\n",
    "\n",
    "\n",
    "\n",
    "# resize_shape = (16, 16, 16)\n",
    "channels = 4\n",
    "interpolation = 1\n",
    "\n",
    "shuffle = True\n",
    "shuffle_data = False\n",
    "\n",
    "resize_shape = (64, 64, 64)\n",
    "print('Train size', len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'seg_probs_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4270e658deed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m transformed_dataset_train = GeneralDataset(csv_file=csv_files['train'],\n\u001b[0m\u001b[1;32m     45\u001b[0m                                            \u001b[0mroot_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                                            \u001b[0mgenomic_csv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenomic_csv_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'seg_probs_transform'"
     ]
    }
   ],
   "source": [
    "train_transformations = myTransforms.Compose([\n",
    "        myTransforms.MinMaxNormalize(),\n",
    "        myTransforms.ScaleToFixed((channels, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=interpolation, \n",
    "                                  channels=channels),\n",
    "        myTransforms.ZeroSprinkle(prob_zero=0.2, prob_true=0.8),\n",
    "        myTransforms.ZeroChannel(prob_zero=0.5),\n",
    "        myTransforms.RandomFlip(),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "seg_transformations = myTransforms.Compose([\n",
    "    myTransforms.ScaleToFixed((1, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=0, \n",
    "                                  channels=1),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "seg_probs_transformations = myTransforms.Compose([\n",
    "        myTransforms.ScaleToFixed((channels, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=interpolation, \n",
    "                                  channels=channels),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "val_transformations = myTransforms.Compose([\n",
    "        myTransforms.MinMaxNormalize(),\n",
    "        myTransforms.ScaleToFixed((channels, resize_shape[0],resize_shape[1],resize_shape[2]), \n",
    "                                  interpolation=interpolation, \n",
    "                                  channels=channels),\n",
    "#         myTransforms.RandomFlip(),\n",
    "        myTransforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "data_transforms = {'train': train_transformations,\n",
    "                   'val':   val_transformations,\n",
    "                   'data':   val_transformations,\n",
    "                   'seg': seg_transformations,\n",
    "                   'seg_probs':seg_probs_transformations\n",
    "                  }\n",
    "\n",
    "\n",
    "\n",
    "transformed_dataset_train = GeneralDataset(csv_file=csv_files['train'],\n",
    "                                           root_dir=image_dir,\n",
    "                                           genomic_csv_file = genomic_csv_files['train'],\n",
    "                                           transform=data_transforms['train'],\n",
    "                                           seg_transform=data_transforms['seg'],\n",
    "                                           seg_probs_transform=data_transforms['seg_probs'],\n",
    "                                           label='cluster',\n",
    "                                           classes=classes,\n",
    "                                           dataformat=dataformat,\n",
    "                                           returndims=resize_shape,\n",
    "                                           return_max_slice=False,\n",
    "                                           axial_only=True,\n",
    "                                           cluster_column=cluster_column,\n",
    "                                           brats2tcia_df=brats2tcia_df,\n",
    "                                           modality=None)\n",
    "\n",
    "transformed_dataset_val = GeneralDataset(csv_file=csv_files['val'],\n",
    "                                         root_dir=image_dir,\n",
    "                                         genomic_csv_file = genomic_csv_files['val'],\n",
    "                                         transform=data_transforms['val'],\n",
    "                                         seg_transform=data_transforms['seg'],\n",
    "                                         seg_probs_transform=data_transforms['seg_probs'],\n",
    "                                         label='cluster',\n",
    "                                         classes=classes,\n",
    "                                         dataformat=dataformat,\n",
    "                                         returndims=resize_shape,\n",
    "                                         cluster_column=cluster_column,\n",
    "                                         brats2tcia_df=brats2tcia_df,\n",
    "                                         modality=None)\n",
    "\n",
    "\n",
    "transformed_dataset_data = GeneralDataset(csv_file=csv_files['data'],\n",
    "                                         root_dir=image_dir,\n",
    "                                          genomic_csv_file = genomic_csv_files['data'],\n",
    "                                         transform=data_transforms['data'],\n",
    "                                          seg_transform=data_transforms['seg'],\n",
    "                                          seg_probs_transform=data_transforms['seg_probs'],\n",
    "                                         label='cluster',\n",
    "                                         classes=classes,\n",
    "                                         dataformat=dataformat,\n",
    "                                         returndims=resize_shape,\n",
    "                                         cluster_column=cluster_column,\n",
    "                                         brats2tcia_df=brats2tcia_df,\n",
    "                                         modality=None)\n",
    "\n",
    "image_datasets = {'train':transformed_dataset_train, \n",
    "                  'val':transformed_dataset_val,\n",
    "                  'data':transformed_dataset_data}\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(image_datasets['train'], batch_size=train_batch_size, shuffle=shuffle, num_workers=4)\n",
    "dataloader_val = DataLoader(image_datasets['val'], batch_size=val_batch_size, shuffle=shuffle, num_workers=4)\n",
    "dataloader_data = DataLoader(image_datasets['data'], batch_size=data_batch_size, shuffle=shuffle_data, num_workers=4)\n",
    "\n",
    "dataloaders = {'train':dataloader_train, 'val':dataloader_val, 'data':dataloader_data}\n",
    "\n",
    "dataset_sizes = {'train':len(image_datasets['train']), \n",
    "                 'val':len(image_datasets['val']), \n",
    "                 'data':len(image_datasets['data'])}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtype_dict = {0:'wildtype', 1:'val'}\n",
    "# for i, data in enumerate(dataloaders['train']):\n",
    "#     (inputs, seg_image, genomic_data, seg_probs), labels,(OS, event), bratsID = data\n",
    "#     inputs, labels = inputs.to(device), labels.to(device)\n",
    "#     print(np.unique(seg_probs))\n",
    "    \n",
    "# #     seg_image2 = seg_probs[0].max(1)[1].data.byte().cpu().numpy()\n",
    "    \n",
    "#     print('**', inputs.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboad: 3D_idh_croppedraw_64x64x64_bs-4_newdataloader_only-gt-idh\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "img_dims = str(resize_shape[0]) + 'x' + str(resize_shape[1]) + 'x' + str(resize_shape[2])\n",
    "model_outfile_dir = '3D_' + task + '_croppedraw_' + img_dims +'_bs-' + str(train_batch_size) + '_newdataloader_only-gt-idh'\n",
    "print('tensorboad:', model_outfile_dir)\n",
    "writer = SummaryWriter('runs1/'+model_outfile_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss weights: tensor([1.0364, 1.0000], device='cuda:0')\n",
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training . . . \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best ACC:\t 0.5 \tin epoch 0\n",
      "New Best AUC-acc aveage:\t 0.6221064814814815 \tin epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:27<22:51, 28.00s/it]/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  4%|▍         | 2/50 [00:55<22:18, 27.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best ACC:\t 0.515625 \tin epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  6%|▌         | 3/50 [01:23<21:50, 27.89s/it]/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  8%|▊         | 4/50 [01:51<21:25, 27.94s/it]/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 10%|█         | 5/50 [02:19<20:52, 27.83s/it]/app/software/scikit-learn/0.23.1-foss-2020a-Python-3.8.2/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      " 14%|█▍        | 7/50 [03:14<19:51, 27.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best AUC:\t 0.59375 \tin epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 8/50 [03:42<19:24, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best ACC:\t 0.5283564814814814 \tin epoch 7\n",
      "New Best ACC:\t 0.5920138888888888 \tin epoch 8\n",
      "New Best AUC:\t 0.6655092592592593 \tin epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 9/50 [04:10<19:00, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best AUC-acc aveage:\t 0.6287615740740741 \tin epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [05:04<17:53, 27.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best ACC:\t 0.6273148148148149 \tin epoch 11\n",
      "New Best AUC:\t 0.6712962962962963 \tin epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 12/50 [05:32<17:33, 27.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best AUC-acc aveage:\t 0.6493055555555556 \tin epoch 11\n",
      "New Best ACC:\t 0.6319444444444444 \tin epoch 12\n",
      "New Best AUC:\t 0.7002314814814815 \tin epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 13/50 [06:01<17:13, 27.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best AUC-acc aveage:\t 0.666087962962963 \tin epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [07:23<15:40, 27.66s/it]"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "best_model_loc = '../pretrained/espnet_3d_brats.pth'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cluster_df = csv_files['train'][task]\n",
    "_, cnts = np.unique(cluster_df, return_counts=True)\n",
    "loss_weights = (np.ones(num_classes)/cnts)*np.max(cnts)\n",
    "loss_weights = torch.FloatTensor(loss_weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=loss_weights)\n",
    "print('loss weights:', loss_weights)\n",
    "\n",
    "\n",
    "from train import train\n",
    "from models.Models import SegModel\n",
    "best_auc_list, best_acc_list, best_auc_acc_list = [], [], []\n",
    "epochs = 50\n",
    "iterations = 10\n",
    "for i in range(iterations):\n",
    "    print('Iteration', i)\n",
    "\n",
    "    best_model_loc = '../pretrained/espnet_3d_brats.pth'\n",
    "    esp_model = SegModel(best_model_loc=best_model_loc, inp_res = resize_shape, num_classes=num_classes)\n",
    "    esp_model = esp_model.to(device=device)\n",
    "\n",
    "    optimizer_esp = optim.Adam(esp_model.parameters(), lr=0.0005) # change to adam\n",
    "    exp_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer_esp, \n",
    "                                                         mode='min', \n",
    "                                                         factor=0.1, \n",
    "                                                         patience=10, # number of epochs with no change \n",
    "                                                         verbose=True, \n",
    "                                                         threshold=0.0001, \n",
    "                                                         threshold_mode='rel', \n",
    "                                                         cooldown=0, \n",
    "                                                         min_lr=0, \n",
    "                                                         eps=1e-08)\n",
    "\n",
    "\n",
    "    model, best_wts, best_auc, best_acc, best_auc_acc = train(model=esp_model, \n",
    "                       dataloaders=dataloaders,\n",
    "                       data_transforms=data_transforms,\n",
    "                       criterion = criterion, \n",
    "                       optimizer=optimizer_esp, \n",
    "                       scheduler=exp_scheduler,\n",
    "                       writer=writer,\n",
    "                       num_epochs=epochs, \n",
    "                       verbose=False, \n",
    "                       device=device,\n",
    "                       dataset_sizes=dataset_sizes,\n",
    "                       channels=1,\n",
    "                       resize_shape=resize_shape,\n",
    "                       classes=class_names,\n",
    "                       weight_outfile_prefix=model_outfile_dir)\n",
    "    del esp_model\n",
    "    del model\n",
    "    \n",
    "    best_auc_list.append(best_auc)\n",
    "    best_acc_list.append(best_acc)\n",
    "    best_auc_acc_list.append(best_auc_acc)\n",
    "    \n",
    "    \n",
    "    results_outfile_dir = model_outfile_dir + '_epochs-' + str(epochs) +'_iterations-' + str(iterations)\n",
    "            \n",
    "    if not os.path.exists('../model_weights/results/'):\n",
    "        os.makedirs('../model_weights/results/')\n",
    "            \n",
    "    with open('../model_weights/results/auc_' + results_outfile_dir + '.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(best_auc_list, fp)\n",
    "\n",
    "    with open('../model_weights/results/acc_' + results_outfile_dir + '.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(best_acc_list, fp)\n",
    "    \n",
    "    with open('../model_weights/results/avg_auc_acc_' + results_outfile_dir + '.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(best_auc_acc_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Two bad epochs (should redo) (March 8th)\n",
    "\n",
    "50 epoch; 10 loops\n",
    "\n",
    "3D_idh_croppedraw_64x64x64_bs-4_newdataloader\n",
    "\n",
    "    auc std: 0.08738088661629888\n",
    "    auc mean: 0.8121527777777778\n",
    "    \n",
    "    acc std: 0.08901614275582172\n",
    "    acc mean: 0.7819444444444444\n",
    "---\n",
    "tensorboad: 3D_idh_croppedraw_64x64x64_bs-4_newdataloader_only-gt-idh (wrong optimizer!!)\n",
    "\n",
    "    auc std: 0.02907397270859894\n",
    "    auc mean: 0.871875\n",
    "    \n",
    "    acc std: 0.046718130289025175\n",
    "    acc mean: 0.8065972222222222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(best_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(best_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(best_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [ 0.8217592592592593,\n",
    " 0.8668981481481481,\n",
    " 0.8796296296296297,\n",
    " 0.8263888888888888,\n",
    " 0.8518518518518519,\n",
    " 0.861111111111111,\n",
    " 0.8553240740740741,\n",
    " 0.8726851851851852]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
